{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "[]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\silvh\\OneDrive\\lighthouse\\custom_python\")\n",
    "import os\n",
    "from silvhua import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the option to wrap text within cells\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wrangling import filter_df_all_conditions, filter_df_any_condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `SimpleSequentialChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "def create_LLMChain(template, input_variables, output_key, llm=OpenAI(temperature=0.7, max_tokens=100)):\n",
    "    \"\"\"\n",
    "    Create an LLMChain object.\n",
    "    Parameters:\n",
    "        - template (str): The template for the prompt, i.e. the value of the `template` \n",
    "            parameter in the PromptTemplate class.\n",
    "        - input_variables (List[str]) \n",
    "        - output_key (str): The key of the output variable.\n",
    "        - llm (OpenAI object): Default is OpenAI()\n",
    "\n",
    "    Returns:\n",
    "        - LLMChain object\n",
    "    \"\"\"\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=template, input_variables=input_variables)\n",
    "    chain = LLMChain(\n",
    "        llm=llm, prompt_template=prompt_template, output_key=output_key)\n",
    "    return chain\n",
    "\n",
    "def analyze_text_sentiment(text, llm=OpenAI(temperature=0.7, max_tokens=100)):\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of a text.\n",
    "    Parameters:\n",
    "        - text (str): The text to analyze.\n",
    "        - llm (OpenAI object): Default is OpenAI()\n",
    "\n",
    "    Returns:\n",
    "        - sentiment (str): The sentiment of the text.\n",
    "    \"\"\"\n",
    "    template_root = \"\"\"\n",
    "    You are the owner of a personal training business. You use a Facebook group to as a lead generation tool.\n",
    "    You aim to respond quickly to posts by group members if they request information, \\\n",
    "    express a desire to improve their fitness, or express dissatisfaction with their current fitness.\n",
    "    Given the following member post delimitted by triple backticks, \n",
    "    \"\"\"\n",
    "    templates = {\n",
    "        'sentiment': 'determine the sentiment of the message as \"positive\", \"neutral\", or \"negative\".',\n",
    "        'emotions': 'determine the emotions expressed in the message.',\n",
    "        'respond': 'indicate whether you need to quickly respond to the message or not using \"yes\" or \"no\".',\n",
    "    }\n",
    "    for template in templates:\n",
    "        chain_dict = {}\n",
    "        chain_dict[template] = create_LLMChain(\n",
    "            template_root+templates[template]+' ```{text}```', \n",
    "            input_variables=['text'], llm=llm)\n",
    "    overall_chain = SequentialChain(\n",
    "        chains = [chain for chain in chain_dict.values()], \n",
    "        input_variables = ['text' for chain in chain_dict.values()],\n",
    "        output_variables = list(chain_dict.keys())\n",
    "    )\n",
    "    return overall_chain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *End of Page*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
